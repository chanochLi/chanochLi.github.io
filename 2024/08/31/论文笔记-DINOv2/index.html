<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>[论文笔记] DINOv2 | Chanoch的博客</title><meta name="author" content="Chanoch Li"><meta name="copyright" content="Chanoch Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="信息Title: DINOv2: Learning Robust Visual Features  without Supervision Author: Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza,"><meta property="og:type" content="article"><meta property="og:title" content="[论文笔记] DINOv2"><meta property="og:url" content="https://blog.chanoch.top/2024/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv2/index.html"><meta property="og:site_name" content="Chanoch的博客"><meta property="og:description" content="信息Title: DINOv2: Learning Robust Visual Features  without Supervision Author: Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza,"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://blog.chanoch.top/img/avatar.png"><meta property="article:published_time" content="2024-08-31T12:25:14.000Z"><meta property="article:modified_time" content="2025-09-04T04:51:12.287Z"><meta property="article:author" content="Chanoch Li"><meta property="article:tag" content="自监督学习"><meta property="article:tag" content="对比学习"><meta property="article:tag" content="图像表征"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://blog.chanoch.top/img/avatar.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "[论文笔记] DINOv2",
  "url": "https://blog.chanoch.top/2024/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv2/",
  "image": "https://blog.chanoch.top/img/avatar.png",
  "datePublished": "2024-08-31T12:25:14.000Z",
  "dateModified": "2025-09-04T04:51:12.287Z",
  "author": [
    {
      "@type": "Person",
      "name": "Chanoch Li",
      "url": "https://blog.chanoch.top/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/avatar.png"><link rel="canonical" href="https://blog.chanoch.top/2024/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"[论文笔记] DINOv2",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Chanoch的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">[论文笔记] DINOv2</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">[论文笔记] DINOv2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-08-31T12:25:14.000Z" title="发表于 2024-08-31 20:25:14">2024-08-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-04T04:51:12.287Z" title="更新于 2025-09-04 12:51:12">2025-09-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">1.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>5分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:30,&quot;messagePrev&quot;:&quot;自从上次更新，已经过了&quot;,&quot;messageNext&quot;:&quot;天，文章内容可能已经过时。&quot;,&quot;postUpdate&quot;:&quot;2025-09-04 12:51:12&quot;}" hidden></div><h1 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h1><p>Title: DINOv2: Learning Robust Visual Features without Supervision</p><p>Author: <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Oquab,+M">Maxime Oquab</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Darcet,+T">Timothée Darcet</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Moutakanni,+T">Théo Moutakanni</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Vo,+H">Huy Vo</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Szafraniec,+M">Marc Szafraniec</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Khalidov,+V">Vasil Khalidov</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Fernandez,+P">Pierre Fernandez</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Haziza,+D">Daniel Haziza</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Massa,+F">Francisco Massa</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=El-Nouby,+A">Alaaeldin El-Nouby</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Assran,+M">Mahmoud Assran</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Ballas,+N">Nicolas Ballas</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Galuba,+W">Wojciech Galuba</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Howes,+R">Russell Howes</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Huang,+P">Po-Yao Huang</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Li,+S">Shang-Wen Li</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Misra,+I">Ishan Misra</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Rabbat,+M">Michael Rabbat</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Sharma,+V">Vasu Sharma</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Synnaeve,+G">Gabriel Synnaeve</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Xu,+H">Hu Xu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Jegou,+H">Hervé Jegou</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Mairal,+J">Julien Mairal</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Labatut,+P">Patrick Labatut</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Joulin,+A">Armand Joulin</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Bojanowski,+P">Piotr Bojanowski</a></p><p>Publish: TMLR</p><p>Year: 2023</p><p>Code: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/dinov2?tab=readme-ov-file">https://github.com/facebookresearch/dinov2?tab=readme-ov-file</a></p><p>Keyword:</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>生成视觉基础模型相对有效的是文字引导的预训练</p><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/image-20250831201948363.png" alt="image-20250831201948363"></p><p>然而：</p><ul><li>由于文字只能大致给图像做标注，会导致复杂的像素信息不能表露•(缺乏像素理解能力)</li><li>同时需要图像-文本对(需要模态对齐获取高质量数据)</li></ul><blockquote><p>MAE需要下游任务微调</p></blockquote><p>现有的自监督的缺陷：</p><ul><li>在相对较小的数据集(ImageNet-1k)上训练，无法大规模拓展</li><li>大规模预训练使用uncurated datasets(没有仔细挑选，自动爬取，系统标注，质量不高)</li></ul><p>作者对自监督的分类：</p><ul><li>图像内自我的自监督：重上色，预测变化，path重排序。。。MAE</li><li>图像间的对比：可以给予物体级和聚类</li></ul><blockquote><p>由此，对比级可以较好的冻结特征，但难以scale</p></blockquote><p>scaling:</p><blockquote><p>scaling不仅仅针对模型，还要针对数据</p></blockquote><ul><li>作者认为现有的模型scale受限于数据质量，需要在微调之后测试</li></ul><p>数据清洗：</p><ul><li>许多方法会使用元数据或者预训练的视觉编码器来去除不好的数据</li></ul><p>贡献：</p><ul><li>在仔细挑选的数据上的大规模自监督预训练</li><li>改进在大规模预训练过程上的稳定和加速技术</li><li>使用一个聚类技术建立了自动化的分离和平衡数据的过程，最终收集到142M图像</li></ul><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/image-20250308103810971.png" alt="image-20250308103810971"></p><h4 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h4><p>标记好的数据源为：</p><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/image-20250308103908350.png" alt="image-20250308103908350"></p><p>仔细挑选的数据包含了ImageNet-22k，ImageNet-1k的训练集，Google Landmarks和其它一些数据集，未仔细挑选的数据集使用了公开爬取的数据</p><blockquote><p>公开爬取数据包含<img>标签包含的数据，除去了不安全或域名限制的数据，并进行后处理(PCA hash去重，NSFW筛选，blur可辨认的人脸)，获取1.2B图像</p></blockquote><p>使用图像去重方法(<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2202.10261">https://arxiv.org/abs/2202.10261</a>)去除了近似重复的图像，并去除了与验证和测试集相似的数据</p><p>图像检索：</p><ul><li><p>使用在ImageNet-22k上自监督训练的ViT-H&#x2F;16，并使用cosine相似度计算图像间距离</p></li><li><p>再对所有未挑选数据集，用k近邻聚类找到与现有数据集相似的图像</p><ul><li><p>如果检索数据很大，对每张图像提取N(4)张</p><blockquote><p>4可以避免一些由于多张检索到相同的图像</p></blockquote></li><li><p>如果很小，从簇中采样M张</p></li></ul></li></ul><p>优势：</p><ul><li><p>约束数据集数据分布，趋近于标注良好的数据集，提升数据集质量</p></li><li><p>减少数据冗余，并增加数据集的多样性</p></li></ul><blockquote><p>用Faiss库完成</p></blockquote><blockquote><p>20个节点的8卡v100-32GB在两天之内完成</p></blockquote><h2 id="对比自监督"><a href="#对比自监督" class="headerlink" title="对比自监督"></a>对比自监督</h2><p>DINO和iBOT损失的结合，并使用了the centering of SwAV，增加了一个正则化项和短的高分辨率训练阶段</p><ul><li><p>图像级目标：使用学生ViT的class token，经过DINO head(MLP和softmax)获取$p_s$，使用教师ViT的class token经过DINO head和移动平均中心化获取$p_t$，用交叉熵来获取相似度：<br>$$<br>\mathcal{L}_{D I N O}&#x3D;-\sum p_t \log p_s<br>$$</p><p>$$<br>P_t^{\prime}&#x3D;P_t-\mu_t<br>$$</p><p>教师网络使用EMA进行更新(使用学生网络和过去网络的加权)：<br>$$<br>\theta_t&#x3D;\lambda \theta_{t-1}+(1-\lambda) \theta_s<br>$$</p></li><li><p>patch级目标：随机掩码学生网络的一些patch，使用学生网络的iBOT head来处理掩码token，同样，使用教师网络的iBOT头处理掩码对应的可见token，同样使用于之前类似的softmax和中心化步骤：<br>$$<br>\mathcal{L}<em>{i B O T}&#x3D;-\sum_i p</em>{t i} \log p_{s i}<br>$$</p></li><li><p>不统一head的权重：DINO和iBOT head中都有一个可学习的MLP，在大规模情况下，不共享效果更好</p><blockquote><p>尽管在小规模对比学习中，共享DINO和iBOT head中的MLP效果更好，但大规模条件下不共享权重效果更好(采用相同的head时会出现图像上过拟合，patch上欠拟合的现象，选择不同的head效果更好)</p></blockquote></li><li><p>Sinkhorn-Knopp centering：在教师模型上使用3次Sinkhorn-Knopp centering来替代softmax使得更加稳定</p></li><li><p>KoLeo正则化：可以在batch中得到更均匀的分布<br>$$<br>\mathcal{L}<em>{\text {koleo }}&#x3D;-\frac{1}{n} \sum</em>{i&#x3D;1}^n \log \left(d_{n, i}\right)<br>$$<br>其中，$d_{n, i}&#x3D;\min _{j \neq i}\left|x_i-x_j\right|$</p><blockquote><p>在计算KoLeo之前，还对特征进行了l2正则化</p></blockquote></li><li><p>分辨率：提高分辨率对于像素级下游任务很重要，但很耗资源，由此只在预训练最后引入$518\times518$分辨率的图像</p></li></ul><h2 id="高效实现"><a href="#高效实现" class="headerlink" title="高效实现"></a>高效实现</h2><ul><li><p>更高效attention：使用了FlashAttention，由于硬件实现，每个attention头的维度为64的倍数，总的维度为256的倍数时很高效，由此，ViT-g使用了1536的维度和24head，而不是原版1408维度和16head</p></li><li><p>Sequence packing：DINO需要在局部裁剪和全局裁剪(输出维度不同)，为了高效，将其拼接在一起，同时送入transformer，并使用mask进行隔离，也使用了xFormers库</p></li><li><p>高效的随机深度：实现了一种改进版本的<code>stochastic depth</code>方法，它跳过了被丢弃的残差的计算，而不是对结果进行屏蔽</p></li><li><p>Fully-Sharded Data Parallel(FSDP)：使用AdamW需要stuent，teacher，optimizer的一阶和二阶动量，将模型副本分片放置在多个GPU中，模型大小不受耽搁GPU内存限制，并且节省通信成本</p><blockquote><p>传统gradient all-reduce operation需要将梯度从不同GPU上收集组合成单个梯度张量，使用float32进行，而FSDP可以使用float16计算</p></blockquote></li><li><p>模型蒸馏：小模型是从大模型中蒸馏出来，在蒸馏过程中，与预训练类似，只是将教师网络冻结，移除了mask和随机深度，使用了iBOT loss，用EMA更新</p></li></ul><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/image-20250831202303436.png" alt="image-20250831202303436"></p><h2 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h2><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/image-20250308145843590.png" alt="image-20250308145843590"></p><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/image-20250831202315434.png" alt="image-20250831202315434"></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.chanoch.top">Chanoch Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.chanoch.top/2024/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv2/">https://blog.chanoch.top/2024/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.chanoch.top" target="_blank">Chanoch的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">自监督学习</a><a class="post-meta__tags" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E8%A1%A8%E5%BE%81/">图像表征</a></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2024/12/08/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-ARM/" title="[论文笔记] ARM"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">[论文笔记] ARM</div></div><div class="info-2"><div class="info-item-1">信息Title: Autoregressive Pretraining with Mamba in Vision Author: Sucheng Ren, Xianhang Li, Haoqin Tu, Feng Wang, Fangxun Shu, Lei Zhang, Jieru Mei, Linjie Yang, Peng Wang, Heng Wang, Alan Yuille, Cihang Xie Year: 2024 Publish: arxiv Code:...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/08/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv3/" title="[论文笔记] DINOv3"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-24</div><div class="info-item-2">[论文笔记] DINOv3</div></div><div class="info-2"><div class="info-item-1">信息Title: DINOv3 Author: Oriane Siméoni, Huy V. Vo, Maximilian Seitzer, Federico Baldassarre, Maxime Oquab, Cijo Jose, Vasil Khalidov, Marc Szafraniec, Seungeun Yi, Michaël Ramamonjisoa, Francisco Massa, Daniel Haziza, Luca Wehrstedt, Jianyuan...</div></div></div></a><a class="pagination-related" href="/2025/04/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-webssl/" title="[论文笔记] Web-SSL"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-27</div><div class="info-item-2">[论文笔记] Web-SSL</div></div><div class="info-2"><div class="info-item-1">信息Title: Scaling Language-Free Visual Representation Learning Author: David Fan, Shengbang Tong, Jiachen Zhu, Koustuv Sinha, Zhuang Liu, Xinlei Chen, Michael Rabbat, Nicolas Ballas, Yann LeCun, Amir Bar, Saining Xie Year: 2025 Publish:...</div></div></div></a><a class="pagination-related" href="/2025/07/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dove/" title="[论文笔记] dove"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-27</div><div class="info-item-2">[论文笔记] dove</div></div><div class="info-2"><div class="info-item-1">信息Title: Images are Worth Variable Length of Representations Author: Lingjun Mao, Rodolfo Corona, Xin Liang, Wenhao Yan, Zineng Tang Year: 2025 Publish: arxiv Organization: University of California, University of Washington Code:...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">Chanoch Li</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/chanochLi" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="mailto:kujou@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#4a7dbe"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF"><span class="toc-number">1.</span> <span class="toc-text">信息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">1.1.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="toc-number">1.2.0.1.</span> <span class="toc-text">数据源</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E8%87%AA%E7%9B%91%E7%9D%A3"><span class="toc-number">1.3.</span> <span class="toc-text">对比自监督</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%95%88%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.4.</span> <span class="toc-text">高效实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%95%88%E6%9E%9C"><span class="toc-number">1.5.</span> <span class="toc-text">实验效果</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv3/" title="[论文笔记] DINOv3">[论文笔记] DINOv3</a><time datetime="2025-08-24T11:20:48.000Z" title="发表于 2025-08-24 19:20:48">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/10/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-VAR/" title="[论文笔记] VAR">[论文笔记] VAR</a><time datetime="2025-08-10T11:20:48.000Z" title="发表于 2025-08-10 19:20:48">2025-08-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dove/" title="[论文笔记] dove">[论文笔记] dove</a><time datetime="2025-07-27T12:59:29.000Z" title="发表于 2025-07-27 20:59:29">2025-07-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-BitNetV2/" title="[论文笔记] BitNetV2">[论文笔记] BitNetV2</a><time datetime="2025-05-25T12:25:14.000Z" title="发表于 2025-05-25 20:25:14">2025-05-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-BitNet/" title="[论文笔记] BitNet">[论文笔记] BitNet</a><time datetime="2025-05-24T12:25:14.000Z" title="发表于 2025-05-24 20:25:14">2025-05-24</time></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"><div id="footer-wrap"><div class="copyright">&copy;2025 By Chanoch Li</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'all',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>