<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>[论文笔记] Web-SSL | Chanoch的博客</title><meta name="author" content="Chanoch Li"><meta name="copyright" content="Chanoch Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="信息Title: Scaling Language-Free Visual Representation Learning Author: David Fan, Shengbang Tong, Jiachen Zhu, Koustuv Sinha, Zhuang Liu, Xinlei Chen, Michael Rabbat, Nicolas Ballas, Yann LeCun, Amir B"><meta property="og:type" content="article"><meta property="og:title" content="[论文笔记] Web-SSL"><meta property="og:url" content="https://blog.chanoch.top/2025/04/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-webssl/index.html"><meta property="og:site_name" content="Chanoch的博客"><meta property="og:description" content="信息Title: Scaling Language-Free Visual Representation Learning Author: David Fan, Shengbang Tong, Jiachen Zhu, Koustuv Sinha, Zhuang Liu, Xinlei Chen, Michael Rabbat, Nicolas Ballas, Yann LeCun, Amir B"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://blog.chanoch.top/img/avatar.png"><meta property="article:published_time" content="2025-04-27T12:59:29.000Z"><meta property="article:modified_time" content="2025-09-04T06:06:14.576Z"><meta property="article:author" content="Chanoch Li"><meta property="article:tag" content="对比学习"><meta property="article:tag" content="自监督"><meta property="article:tag" content="视觉大模型"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://blog.chanoch.top/img/avatar.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "[论文笔记] Web-SSL",
  "url": "https://blog.chanoch.top/2025/04/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-webssl/",
  "image": "https://blog.chanoch.top/img/avatar.png",
  "datePublished": "2025-04-27T12:59:29.000Z",
  "dateModified": "2025-09-04T06:06:14.576Z",
  "author": [
    {
      "@type": "Person",
      "name": "Chanoch Li",
      "url": "https://blog.chanoch.top/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/avatar.png"><link rel="canonical" href="https://blog.chanoch.top/2025/04/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-webssl/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"[论文笔记] Web-SSL",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Chanoch的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">[论文笔记] Web-SSL</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">[论文笔记] Web-SSL</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-27T12:59:29.000Z" title="发表于 2025-04-27 20:59:29">2025-04-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-04T06:06:14.576Z" title="更新于 2025-09-04 14:06:14">2025-09-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">1.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>4分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:30,&quot;messagePrev&quot;:&quot;自从上次更新，已经过了&quot;,&quot;messageNext&quot;:&quot;天，文章内容可能已经过时。&quot;,&quot;postUpdate&quot;:&quot;2025-09-04 14:06:14&quot;}" hidden></div><h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p>Title: Scaling Language-Free Visual Representation Learning</p><p>Author: <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Fan,+D">David Fan</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Tong,+S">Shengbang Tong</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Zhu,+J">Jiachen Zhu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Sinha,+K">Koustuv Sinha</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Liu,+Z">Zhuang Liu</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Chen,+X">Xinlei Chen</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Rabbat,+M">Michael Rabbat</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Ballas,+N">Nicolas Ballas</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=LeCun,+Y">Yann LeCun</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Bar,+A">Amir Bar</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/search/cs?searchtype=author&query=Xie,+S">Saining Xie</a></p><p>Year: 2025</p><p>Publish: arxiv</p><p>Organizaition: meta</p><p>Keyword: 视觉基础模型，多模态</p><p>Code: <a target="_blank" rel="noopener" href="https://github.com/dfan/webssl">https://github.com/dfan/webssl</a></p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>现阶段，视觉自监督比对比式语言-图像预训练(CLIP家族)在VQA任务上落后，可能的原因有：</p><ul><li><p>缺少语言信息监督(模型结构因素)：视觉SSL在方法和数据上缺少语言模态的监督，而具有语言监督的多模态模型更偏好VQA</p></li><li><p>在不同的数据上训练(数据因素)：现阶段，视觉SSL通常采用object-centered数据集，而多模态模型采用大规模网络数据集</p><blockquote><p>以往的SSL一般使用ImageNet，ADE20k等object-centered数据集，缺少泛化性，并且无法与其它模型对比</p></blockquote></li></ul><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2022.21.44.png" alt="Screenshot 2025-04-13 at 22.21.44" style="zoom:50%"><p>这种语言监督信息是否是必要的？</p><p>为了公平起见，对比时使用SOTA的MetaCLIP和其数据集，下游任务上采用VQA(通用，视觉问答，视觉推理，OCR，图表解读。。。)，在相同条件设定下对比了视觉SSL和语言-图像模型的性能(VQA和传统图像任务)</p><p>贡献：</p><ul><li><p>在VQA任务上，使用相同数据训练的视觉SSL模型比SOTA的CLIP模型表现更好</p><blockquote><p>也有可能是数据在在MetaCLIP处理的时候变得更好，类似AIM对于数据的处理</p></blockquote></li><li><p>视觉SSL在模型和数据上scale能力很强</p></li><li><p>视觉SSL在传统任务上表现更好</p></li><li><p>以更高的图像比例对OCR，图表理解提升很大</p></li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h4 id="SSL的提升"><a href="#SSL的提升" class="headerlink" title="SSL的提升"></a>SSL的提升</h4><p>作者主要在以下方面对SSL进行了拓展，使用了DINOv2和MAE：</p><ul><li><p>将自监督数据集拓展到billion级别</p><ul><li>使用了MC-2B的图像部分，由此控制数据集分布的影响</li></ul><blockquote><p>但文本不应该也算在分布中吗？</p></blockquote></li><li><p>将模型大小拓展到1B以上</p><ul><li>1B使用ViT-g，2，3，5，7B用其变体</li></ul></li><li><p>使用更偏向于文本的VQA来进行衡量，而不是ImageNet和ADE20k</p><ul><li>传统方法会使用Linear Probe进行衡量，还采用了VQA</li><li>使用了指令微调，数据使用Cambrian-1，LLM使用了Llama-3 8B<ul><li>一层MLP作为模态桥接器进行训练</li><li>微调MLP和LLM</li></ul></li></ul></li></ul><h2 id="scaling能力"><a href="#scaling能力" class="headerlink" title="scaling能力"></a>scaling能力</h2><p>使用了各自原始的代码(DINOv2没有加入高分辨率)和策略</p><h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p>为了：</p><ul><li>找到这种数据量上视觉SSL的性能上限</li><li>看模型是否有任何独特的表现</li></ul><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.00.17.png" alt="Screenshot 2025-04-13 at 23.00.17"></p><p>可以看到：</p><ul><li><p>SSL方法大致能随着数据增长，CLIP方法会在3B时达到顶峰，更多的参数会是浪费</p><blockquote><p>SSL方法也没有衰竭，这也说明大于7B的模型也可以探索</p></blockquote></li></ul><blockquote><p>那么，在数据分布上的探索也是一个方向</p></blockquote><h4 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h4><p>即从1 epoch拓展到0.5epoch～4epoch</p><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.08.22.png" alt="Screenshot 2025-04-13 at 23.08.22"></p><p>可以发现：</p><ul><li><p>只有OCR一直提升，在没有其它模态损失的情况下，更学习到偏向于文本的特征(更集中)</p></li><li><p>随着数据增长，也一直比CLIP好</p></li></ul><p>由此，CLIP的语言监督并没有比视觉SSL有绝对优势：</p><ul><li>CLIP的语言监督在偏向于文本任务的VQA上并没有比视觉SSL有绝对优势</li><li>CLIP在传统任务上落后于视觉SSL</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h4 id="是否适用于其它SSL"><a href="#是否适用于其它SSL" class="headerlink" title="是否适用于其它SSL"></a>是否适用于其它SSL</h4><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.15.07.png" alt="Screenshot 2025-04-13 at 23.15.07"></p><p>生成式的SSL更适合OCR和图表，但在其它方面不如，整体趋势一致</p><blockquote><p>这也揭示了不同的SSL学习的能力不同</p></blockquote><h4 id="使用传统小数据集是否适用"><a href="#使用传统小数据集是否适用" class="headerlink" title="使用传统小数据集是否适用"></a>使用传统小数据集是否适用</h4><p>使用ImageNet-1k进行训练，但性能更差，也没有scaling效果</p><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.20.45.png" alt="Screenshot 2025-04-13 at 23.20.45"></p><blockquote><p>这也对以前一些自监督方法在ImageNet-1k上自监督训练的结果提出了质疑</p></blockquote><p>表明数据集的更多元化，更大对于模型性能的提升，并且预训练数据集分布也会对下游任务影响很大</p><h4 id="在传统任务上表现"><a href="#在传统任务上表现" class="headerlink" title="在传统任务上表现"></a>在传统任务上表现</h4><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.26.31.png" alt="Screenshot 2025-04-13 at 23.26.31"></p><ul><li>比CLIP模型效果显著要好，也没有比DINOv2差多少(在没有高分辨率和DINOv2数据更接近传统任务的情况下)</li></ul><blockquote><p>但DINOv2最大是1B左右的</p></blockquote><ul><li>但在传统任务上scaling表现没那么好</li></ul><blockquote><p>这也表明VQA作为一个更多元化任务的衡量</p></blockquote><h4 id="在OCR，图表任务上的提升"><a href="#在OCR，图表任务上的提升" class="headerlink" title="在OCR，图表任务上的提升"></a>在OCR，图表任务上的提升</h4><ul><li>传统数据上不含表格，文档，网络数据上包含文档，文字</li></ul><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.35.08.png" alt="Screenshot 2025-04-13 at 23.35.08"></p><p>50.3%去除了不含文字的图片，1.3%只包含表格，文档。。。</p><p>而且更奇怪的是，遮挡掉数据会提升整体性能</p><h2 id="为什么缺失语言模态"><a href="#为什么缺失语言模态" class="headerlink" title="为什么缺失语言模态"></a>为什么缺失语言模态</h2><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.42.56.png" alt="Screenshot 2025-04-13 at 23.42.56"></p><p>计算了模型的对齐分数，趋势：</p><ul><li>在更广泛数据集上，对齐分数更高</li><li>更大的模型对齐分数稍微更高</li><li>更多的数据对齐分数更高</li></ul><blockquote><p>其实无论文本还是图像，都在追求一种更广泛而更紧密的特征表达，由此对齐分数更高</p></blockquote><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://raw.githubusercontent.com/chanochLi/blog-pic/main/img/Screenshot%202025-04-13%20at%2023.53.03.png" alt="Screenshot 2025-04-13 at 23.53.03"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>文章围绕语言监督信息是否是必要的？的问题展开：</p><ul><li><p>进一步训练数据探索的可能—-多样性，分布，数据规模，图表。。。</p></li><li><p>视觉SSL任务对比CLIP家族在很多方面(即使是更偏向于文本的VQA)还有优势，多模态大模型的视觉组件更可以利用视觉SSL探索进行构建</p></li></ul><p>但存在一定局限：</p><ul><li><p>不支持零样本(需要对齐文字支持零样本学习)</p></li><li><p>虽然超越CLIP，但在许多任务上比不上DINOv2</p></li><li><p>只使用了Llama-3 8B Instruct，假定LLM不会带来影响</p></li><li><p>数据和模型大小局限</p></li></ul></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.chanoch.top">Chanoch Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.chanoch.top/2025/04/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-webssl/">https://blog.chanoch.top/2025/04/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-webssl/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.chanoch.top" target="_blank">Chanoch的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%9B%91%E7%9D%A3/">自监督</a><a class="post-meta__tags" href="/tags/%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/">视觉大模型</a></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/05/04/Jetson%E6%95%99%E7%A8%8B/" title="Jetson+gemini 2相机配置教程"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Jetson+gemini 2相机配置教程</div></div><div class="info-2"><div class="info-item-1">Jetson平台和Gemini 2相机平台Jetson Orin NX&#x2F;Jetson AGX OrinNVIDIA Jetson™ 是专为机器人和嵌入式边缘 AI 应用打造的平台，设计紧凑但功能强大的计算机，并由NVIDIA JetPack™...</div></div></div></a><a class="pagination-related" href="/2024/12/22/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-AIM/" title="[论文笔记] AIM"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">[论文笔记] AIM</div></div><div class="info-2"><div class="info-item-1">信息Title: Scalable Pre-training of Large Autoregressive Image Models Author: Alaaeldin El-Nouby, Michal Klein, Shuangfei Zhai, Miguel Angel Bautista, Alexander Toshev, Vaishaal Shankar, Joshua M Susskind, Armand Joulin Year: 2024 Jan Publish: ICML...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/08/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv3/" title="[论文笔记] DINOv3"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-24</div><div class="info-item-2">[论文笔记] DINOv3</div></div><div class="info-2"><div class="info-item-1">信息Title: DINOv3 Author: Oriane Siméoni, Huy V. Vo, Maximilian Seitzer, Federico Baldassarre, Maxime Oquab, Cijo Jose, Vasil Khalidov, Marc Szafraniec, Seungeun Yi, Michaël Ramamonjisoa, Francisco Massa, Daniel Haziza, Luca Wehrstedt, Jianyuan...</div></div></div></a><a class="pagination-related" href="/2024/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv2/" title="[论文笔记] DINOv2"><div class="cover" style="background:var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-31</div><div class="info-item-2">[论文笔记] DINOv2</div></div><div class="info-2"><div class="info-item-1">信息Title: DINOv2: Learning Robust Visual Features without Supervision Author: Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">Chanoch Li</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/chanochLi" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="mailto:kujou@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#4a7dbe"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF"><span class="toc-number">1.</span> <span class="toc-text">信息</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SSL%E7%9A%84%E6%8F%90%E5%8D%87"><span class="toc-number">3.0.1.</span> <span class="toc-text">SSL的提升</span></a></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#scaling%E8%83%BD%E5%8A%9B"><span class="toc-number">4.</span> <span class="toc-text">scaling能力</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.0.1.</span> <span class="toc-text">模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE"><span class="toc-number">4.0.2.</span> <span class="toc-text">数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">5.</span> <span class="toc-text">问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%98%AF%E5%90%A6%E9%80%82%E7%94%A8%E4%BA%8E%E5%85%B6%E5%AE%83SSL"><span class="toc-number">5.0.1.</span> <span class="toc-text">是否适用于其它SSL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E4%BC%A0%E7%BB%9F%E5%B0%8F%E6%95%B0%E6%8D%AE%E9%9B%86%E6%98%AF%E5%90%A6%E9%80%82%E7%94%A8"><span class="toc-number">5.0.2.</span> <span class="toc-text">使用传统小数据集是否适用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8%E4%BC%A0%E7%BB%9F%E4%BB%BB%E5%8A%A1%E4%B8%8A%E8%A1%A8%E7%8E%B0"><span class="toc-number">5.0.3.</span> <span class="toc-text">在传统任务上表现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8OCR%EF%BC%8C%E5%9B%BE%E8%A1%A8%E4%BB%BB%E5%8A%A1%E4%B8%8A%E7%9A%84%E6%8F%90%E5%8D%87"><span class="toc-number">5.0.4.</span> <span class="toc-text">在OCR，图表任务上的提升</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E7%BC%BA%E5%A4%B1%E8%AF%AD%E8%A8%80%E6%A8%A1%E6%80%81"><span class="toc-number">6.</span> <span class="toc-text">为什么缺失语言模态</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">7.</span> <span class="toc-text">实验</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number"></span> <span class="toc-text">总结</span></a></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-DINOv3/" title="[论文笔记] DINOv3">[论文笔记] DINOv3</a><time datetime="2025-08-24T11:20:48.000Z" title="发表于 2025-08-24 19:20:48">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/10/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-VAR/" title="[论文笔记] VAR">[论文笔记] VAR</a><time datetime="2025-08-10T11:20:48.000Z" title="发表于 2025-08-10 19:20:48">2025-08-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-dove/" title="[论文笔记] dove">[论文笔记] dove</a><time datetime="2025-07-27T12:59:29.000Z" title="发表于 2025-07-27 20:59:29">2025-07-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/25/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-BitNetV2/" title="[论文笔记] BitNetV2">[论文笔记] BitNetV2</a><time datetime="2025-05-25T12:25:14.000Z" title="发表于 2025-05-25 20:25:14">2025-05-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0-BitNet/" title="[论文笔记] BitNet">[论文笔记] BitNet</a><time datetime="2025-05-24T12:25:14.000Z" title="发表于 2025-05-24 20:25:14">2025-05-24</time></div></div></div></div></div></div></main><footer id="footer" style="background:0 0"><div id="footer-wrap"><div class="copyright">&copy;2025 By Chanoch Li</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'all',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>